# File Checksum Validator

**Data Integrity Testing and Corruption Detection**

---

## Introduction

The File Checksum Validator is a comprehensive tool for verifying file integrity using multiple cryptographic hash algorithms. In an era of large file transfers, cloud storage, and software downloads, ensuring that files haven't been corrupted or tampered with is critical for data reliability and security.

A **checksum** (or hash) is a fixed-size fingerprint of a file that changes completely if even a single bit is modified. By comparing checksums before and after transfer, you can detect:
- **Accidental corruption** - Disk errors, network glitches, incomplete downloads
- **Malicious tampering** - Malware injection, unauthorized modifications
- **Data degradation** - Bit rot, storage media failure

CryptoSentinel's validator supports:
- **Multiple algorithms** - MD5, SHA-1, SHA-256, SHA-512
- **Batch verification** - Check many files at once
- **Format detection** - Auto-detect checksum file formats
- **Performance optimization** - Streaming for large files (GB+)

### When to Use This Tool

âœ… **Software downloads** - Verify installer integrity  
âœ… **File transfers** - Confirm successful copy/upload/download  
âœ… **Backup verification** - Ensure backup matches original  
âœ… **Storage integrity** - Detect bit rot and media failure  
âœ… **Digital forensics** - Prove file hasn't been altered  
âœ… **Software distribution** - Publishers providing checksums  

âŒ **Data hiding** - Checksums don't encrypt ([[SHA256-Hash-Implementation]])  
âŒ **Authentication** - Use digital signatures (GPG, RSA) for authenticity  

---

## Algorithm: Cryptographic Hash Functions

### What is a Checksum?

A **cryptographic hash function** takes arbitrary input and produces fixed-size output:

```
File (any size) â†’ Hash Function â†’ Checksum (fixed size)

example.iso (4.7 GB) â†’ SHA-256 â†’ e3b0c44298fc1c14... (64 chars)
```

### Hash Properties Required for Integrity

1. **Deterministic** - Same input always produces same output
2. **Fixed size** - Output length constant regardless of input size
3. **Avalanche effect** - Tiny input change = completely different output
4. **Fast computation** - Efficient for large files
5. **Collision resistant** - Hard to find two inputs with same output
6. **Pre-image resistant** - Can't reverse hash to find original file

### Supported Algorithms

| Algorithm | Output Size | Speed | Security | Use Case |
|-----------|-------------|-------|----------|----------|
| **MD5** | 128 bits (32 hex) | Very Fast | âš ï¸ Broken | Legacy only |
| **SHA-1** | 160 bits (40 hex) | Fast | âš ï¸ Deprecated | Compatibility |
| **SHA-256** | 256 bits (64 hex) | Fast | âœ… Secure | **Recommended** |
| **SHA-512** | 512 bits (128 hex) | Fast (64-bit) | âœ… Secure | Long-term |

**Recommendation hierarchy:**
1. **Best**: SHA-256 (industry standard)
2. **Alternative**: SHA-512 (if available)
3. **Acceptable**: SHA-1 (non-security, compatibility only)
4. **Avoid**: MD5 (unless required by legacy systems)

See [[MD5-Hash-Calculator]] and [[SHA256-Hash-Implementation]] for detailed algorithm explanations.

### Collision Attacks Impact on Integrity

**MD5 collision example:**
```
file_A.exe (legitimate software)
SHA-256: a1b2c3d4...

file_B.exe (malware)
MD5: 5d41402abc... â† Attacker crafted to match
MD5: 5d41402abc... â† Same as file_A!

Checksum verification: âœ“ PASS (but wrong file!)
```

**Why SHA-256 is required:**
- MD5 collisions can be generated in seconds
- SHA-1 collisions demonstrated (Google, 2017)
- SHA-256 has no known practical attacks
- Industry mandates SHA-256+ for security

---

## How It Works: Code Implementation

### Multi-Algorithm Checksum Calculator

```python
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple

class FileChecksumValidator:
    """
    Calculate and verify file checksums with multiple algorithms.
    """
    
    ALGORITHMS = {
        'md5': hashlib.md5,
        'sha1': hashlib.sha1,
        'sha256': hashlib.sha256,
        'sha512': hashlib.sha512
    }
    
    def calculate_checksum(self, 
                          file_path: str, 
                          algorithm: str = 'sha256',
                          chunk_size: int = 8192) -> str:
        """
        Calculate checksum for a file.
        
        Args:
            file_path: Path to file
            algorithm: Hash algorithm ('md5', 'sha1', 'sha256', 'sha512')
            chunk_size: Bytes to read at once (for streaming)
            
        Returns:
            Hexadecimal checksum string
        """
        if algorithm not in self.ALGORITHMS:
            raise ValueError(f"Unsupported algorithm: {algorithm}")
        
        hasher = self.ALGORITHMS[algorithm]()
        
        # Stream file in chunks (memory efficient)
        with open(file_path, 'rb') as f:
            while chunk := f.read(chunk_size):
                hasher.update(chunk)
        
        return hasher.hexdigest()
    
    def calculate_all(self, file_path: str) -> Dict[str, str]:
        """
        Calculate all supported checksums for a file.
        
        Returns:
            Dictionary of {algorithm: checksum}
        """
        results = {}
        
        for algorithm in self.ALGORITHMS:
            results[algorithm] = self.calculate_checksum(file_path, algorithm)
        
        return results
    
    def verify_checksum(self, 
                       file_path: str, 
                       expected: str,
                       algorithm: str = 'sha256') -> bool:
        """
        Verify file checksum matches expected value.
        
        Args:
            file_path: Path to file
            expected: Expected checksum (hex string)
            algorithm: Hash algorithm
            
        Returns:
            True if match, False otherwise
        """
        actual = self.calculate_checksum(file_path, algorithm)
        
        # Case-insensitive comparison
        return actual.lower() == expected.lower()
    
    def detect_algorithm(self, checksum: str) -> str:
        """
        Auto-detect hash algorithm from checksum length.
        
        Args:
            checksum: Hex checksum string
            
        Returns:
            Algorithm name or 'unknown'
        """
        length = len(checksum)
        
        if length == 32:
            return 'md5'
        elif length == 40:
            return 'sha1'
        elif length == 64:
            return 'sha256'
        elif length == 128:
            return 'sha512'
        else:
            return 'unknown'
    
    def verify_directory(self, 
                        directory: str,
                        checksum_file: str) -> List[Tuple[str, bool, str]]:
        """
        Verify all files in directory against checksum file.
        
        Args:
            directory: Directory containing files
            checksum_file: Path to checksum file (format: hash filename)
            
        Returns:
            List of (filename, verified, status_message)
        """
        results = []
        
        # Parse checksum file
        checksums = self._parse_checksum_file(checksum_file)
        
        for filename, expected_checksum in checksums.items():
            file_path = Path(directory) / filename
            
            if not file_path.exists():
                results.append((filename, False, "File not found"))
                continue
            
            # Detect algorithm
            algorithm = self.detect_algorithm(expected_checksum)
            if algorithm == 'unknown':
                results.append((filename, False, "Unknown checksum format"))
                continue
            
            # Calculate and verify
            try:
                actual = self.calculate_checksum(str(file_path), algorithm)
                
                if actual.lower() == expected_checksum.lower():
                    results.append((filename, True, f"âœ“ Verified ({algorithm})"))
                else:
                    results.append((filename, False, 
                                 f"âœ— Mismatch (expected: {expected_checksum}, got: {actual})"))
            except Exception as e:
                results.append((filename, False, f"Error: {str(e)}"))
        
        return results
    
    def _parse_checksum_file(self, checksum_file: str) -> Dict[str, str]:
        """
        Parse checksum file in various formats.
        
        Supported formats:
        - BSD: MD5 (filename) = checksum
        - GNU: checksum  filename
        - Simple: checksum filename
        """
        checksums = {}
        
        with open(checksum_file, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                # Try BSD format: MD5 (file) = hash
                if '(' in line and ')' in line and '=' in line:
                    parts = line.split('=')
                    filename = line[line.find('(')+1:line.find(')')]
                    checksum = parts[1].strip()
                
                # Try GNU/Simple format: hash  file or hash file
                else:
                    parts = line.split(None, 1)
                    if len(parts) == 2:
                        checksum, filename = parts
                        # Remove leading * (binary mode indicator)
                        filename = filename.lstrip('*')
                    else:
                        continue
                
                checksums[filename] = checksum
        
        return checksums
    
    def create_checksum_file(self, 
                           directory: str,
                           output_file: str,
                           algorithm: str = 'sha256',
                           format: str = 'gnu') -> int:
        """
        Create checksum file for all files in directory.
        
        Args:
            directory: Directory to scan
            output_file: Output checksum file path
            algorithm: Hash algorithm
            format: Output format ('gnu', 'bsd', 'simple')
            
        Returns:
            Number of files processed
        """
        dir_path = Path(directory)
        count = 0
        
        with open(output_file, 'w') as f:
            # Write header comment
            f.write(f"# {algorithm.upper()} checksums generated by CryptoSentinel\n")
            f.write(f"# Algorithm: {algorithm}\n")
            f.write(f"# Directory: {directory}\n\n")
            
            for file_path in sorted(dir_path.rglob('*')):
                if file_path.is_file() and file_path != Path(output_file):
                    try:
                        checksum = self.calculate_checksum(str(file_path), algorithm)
                        relative_path = file_path.relative_to(dir_path)
                        
                        if format == 'bsd':
                            f.write(f"{algorithm.upper()} ({relative_path}) = {checksum}\n")
                        elif format == 'gnu':
                            f.write(f"{checksum}  {relative_path}\n")
                        else:  # simple
                            f.write(f"{checksum} {relative_path}\n")
                        
                        count += 1
                    except Exception as e:
                        print(f"Warning: Could not process {file_path}: {e}")
        
        return count
```

### Performance Optimization for Large Files

```python
def calculate_checksum_parallel(file_path: str, 
                               algorithms: List[str]) -> Dict[str, str]:
    """
    Calculate multiple checksums in one file pass.
    More efficient than separate passes for each algorithm.
    """
    hashers = {alg: hashlib.new(alg) for alg in algorithms}
    
    with open(file_path, 'rb') as f:
        while chunk := f.read(8192):
            for hasher in hashers.values():
                hasher.update(chunk)
    
    return {alg: hasher.hexdigest() for alg, hasher in hashers.items()}

# Usage
checksums = calculate_checksum_parallel('large_file.iso', 
                                       ['md5', 'sha256', 'sha512'])
# Single file read, three hashes calculated!
```

---

## Usage Guide: CLI Commands

### Starting the Tool

```bash
python cli.py

# Select: 2. Hashing Tools > 3. File Checksum Validator
```

### Calculate Checksum

```
Choose operation:
1. Calculate checksum (single file)
2. Verify checksum
3. Batch verify (directory)
4. Generate checksum file

Selection: 1

Enter file path: ~/Downloads/ubuntu-22.04-desktop.iso
Algorithm:
  1. MD5 (fast, legacy)
  2. SHA-1 (deprecated)
  3. SHA-256 (recommended) â­
  4. SHA-512 (maximum security)
  5. All algorithms

Selection: 3

ğŸ” Reading file (4.7 GB)...
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%

âœ“ Checksum calculated:

File: ubuntu-22.04-desktop.iso
Size: 4,700,372,992 bytes (4.7 GB)
Algorithm: SHA-256

Checksum:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
a4acfda10b18da50e2ec50ccaf860d7f20b389df8765611142305c0e911d16fd
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Time: 9.2 seconds (511 MB/s)

ğŸ’¾ Save to file? (y/n): y
Saved to: ubuntu-22.04-desktop.iso.sha256
```

### Verify File Integrity

```
Selection: 2

Enter file path: ~/Downloads/ubuntu-22.04-desktop.iso
Enter expected checksum: a4acfda10b18da50e2ec50ccaf860d7f20b389df8765611142305c0e911d16fd

ğŸ” Auto-detecting algorithm... SHA-256 (64 characters)
ğŸ” Calculating checksum...
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100%

âœ“ VERIFICATION SUCCESSFUL!

File: ubuntu-22.04-desktop.iso
Expected: a4acfda10b18da50e2ec50ccaf860d7f20b389df8765611142305c0e911d16fd
Actual:   a4acfda10b18da50e2ec50ccaf860d7f20b389df8765611142305c0e911d16fd

âœ“ File integrity confirmed
âœ“ No corruption detected
âœ“ Safe to use

This means:
  âœ“ Download completed successfully
  âœ“ No network transmission errors
  âœ“ File matches publisher's original
  âœ“ No tampering detected
```

### Batch Directory Verification

```
Selection: 3

Enter directory path: ~/Downloads/backup_2024
Enter checksum file: SHA256SUMS

ğŸ” Parsing checksum file (78 entries)...
ğŸ” Verifying files...

Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 78/78 files

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
VERIFICATION RESULTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Passed: 76 files
âœ— Failed: 2 files
âš  Missing: 0 files

Failed Files:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Filename            â”ƒ Status                 â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ document.pdf        â”‚ âœ— Checksum mismatch    â”‚
â”‚ photo_0042.jpg      â”‚ âœ— Checksum mismatch    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸  Recommendations:
  â€¢ Re-download failed files
  â€¢ Check for disk errors (run fsck/chkdsk)
  â€¢ Verify backup source integrity
  â€¢ Consider bit rot if files are old
```

### Generate Checksum File

```
Selection: 4

Enter directory to scan: ~/project/release
Output file: checksums.sha256
Algorithm: SHA-256
Format:
  1. GNU (checksum  filename)
  2. BSD (SHA256 (filename) = checksum)
  3. Simple (checksum filename)

Format: 1

ğŸ” Scanning directory...
   Found: 156 files

ğŸ” Calculating checksums...
Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 156/156 files

âœ“ Checksum file created!

Output: checksums.sha256
Files processed: 156
Total size: 2.3 GB
Time: 34.7 seconds

Sample content:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# SHA256 checksums generated by CryptoSentinel
a1b2c3d4...  README.md
5e6f7a8b...  setup.py
9c0d1e2f...  src/main.py
...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Distribute this file with your software release!
```

---

## Troubleshooting

### Common Issues

**Problem:** "Checksum doesn't match but file seems fine"  
**Solution:** Check these factors:
- **Line endings**: Windows (CRLF) vs Unix (LF) in text files
- **Transfer mode**: Use binary mode for FTP, not ASCII
- **Metadata**: Some tools include timestamps/permissions
- **Compression**: Recompressed files have different checksums
- **Encoding**: Text file character encoding (UTF-8 vs ISO-8859-1)
- **Solution**: Always checksum in binary mode, use same compression

**Problem:** "Which algorithm should I use?"  
**Solution:** Algorithm selection guide:

**âœ… Recommended: SHA-256**
- Industry standard
- Fast and secure
- Widely supported
- Use for: Software downloads, backups, distribution

**âš ï¸ SHA-1 (if required)**
- Deprecated for security
- OK for non-security integrity checks
- Use for: Git commits (legacy), compatibility

**âŒ Avoid: MD5**
- Cryptographically broken
- Only if required by legacy systems
- Don't use for: Security, verification, new projects

**ğŸ”’ Maximum security: SHA-512**
- Overkill for most uses
- Slightly slower on 32-bit systems
- Use for: Long-term archives, maximum paranoia

**Problem:** "Verification is very slow for large files"  
**Solution:** Performance tips:
- **Normal**: 1 GB file = 2-3 seconds (300-500 MB/s)
- **Slow**: Network drives, encrypted disks, old HDDs
- **Optimization**: Use SSD, read file locally first
- **Multi-file**: Process in parallel (separate files)
- **Can't speed up**: Single file must be read sequentially

**Problem:** "How do I verify downloads from websites?"  
**Solution:** Step-by-step verification:

```bash
# 1. Download both file and checksum
wget https://example.com/software.zip
wget https://example.com/software.zip.sha256

# 2. Verify using command line
sha256sum -c software.zip.sha256

# 3. Or use CryptoSentinel (method above)

# 4. IMPORTANT: Also verify digital signature if available!
gpg --verify software.zip.asc software.zip
```

Checksum only verifies integrity, signature verifies authenticity!

**Problem:** "Old backup failed verification - is it corrupted?"  
**Solution:** Could be **bit rot** (storage degradation):
- Magnetic media degrades over time
- Cosmic rays can flip bits
- Drive firmware errors
- Silent data corruption
- **Prevention**: Regular integrity checks, redundant copies (RAID, 3-2-1 backup)
- **Detection**: Compare multiple copies, check SMART data
- **Recovery**: Restore from other backup, check source media

---

## Pros and Cons

### âœ… Advantages

**Reliable Corruption Detection**
- Detects single-bit errors in GB+ files
- 2^256 possible SHA-256 values (astronomically large)
- Probability of false positive: Effectively zero
- Mathematical guarantee of integrity

**Fast Performance**
- SHA-256: 300-500 MB/s (modern CPU)
- Process 1 TB in ~30-45 minutes
- Streaming (no memory limit)
- Hardware acceleration available (AES-NI)

**Universal Standard**
- All operating systems support
- Every programming language has libraries
- Industry-wide adoption
- Consistent across platforms

**Multiple Use Cases**
- Software distribution (verify downloads)
- Backup verification (detect bit rot)
- Forensics (prove file unchanged)
- Deduplication (identify identical files)

### âŒ Disadvantages

**Cannot Detect Malicious Modifications (Without Trust)**
- Attacker can replace both file and checksum
- Need trusted source for checksum
- **Solution**: Use digital signatures (GPG, code signing)
- Checksum file must be obtained securely

**No Error Correction**
- Only detects errors, doesn't fix them
- Need original or backup to recover
- Contrast: Error-correcting codes (ECC, RAID) can fix errors
- **Solution**: Keep multiple copies, use RAID

**Time-Consuming for Large Files**
- 1 TB file = ~30-45 minutes to checksum
- Must read entire file
- Cannot parallelize single file
- **Mitigation**: Checksum during transfer, cache results

**Storage Overhead**
- Checksum files add storage cost
- Large directories: 1 checksum file per directory
- Must keep checksums updated when files change
- **Mitigation**: Minimal (few KB per thousand files)

**False Sense of Security**
- Users may think checksum = authenticated
- Checksums don't verify source authenticity
- MITM attacks can replace both file and checksum
- **Solution**: Combine with digital signatures

### Comparison: Checksum vs Signature vs Backup

| Feature | Checksum | Digital Signature | Backup/RAID |
|---------|----------|------------------|-------------|
| **Detects corruption** | âœ… Yes | âœ… Yes | âœ… Yes |
| **Verifies authenticity** | âŒ No | âœ… Yes | âŒ No |
| **Error correction** | âŒ No | âŒ No | âœ… Yes (RAID) |
| **Requires key** | âŒ No | âœ… Yes (public key) | âŒ No |
| **Speed** | Fast | Slower | Fast (RAID) |
| **Use case** | Integrity | Authenticity | Recovery |

**Best practice:** Use all three!
- **Checksum**: Verify integrity
- **Signature**: Verify authenticity
- **Backup**: Enable recovery

---

## Related Tools

- **[[SHA256-Hash-Implementation]]** - Detailed SHA-256 algorithm explanation
- **[[MD5-Hash-Calculator]]** - Legacy MD5 (with security warnings)
- **[[Base64-Encoder-Decoder]]** - Encoding checksums for transmission

---

## References

### Standards and Specifications
- **FIPS 180-4**: Secure Hash Standard (SHA-2)
- **RFC 1321**: MD5 specification (historical)
- **ISO/IEC 10118**: Hash functions standard
- **NIST SP 800-107**: Hash algorithm security recommendations

### Checksum File Formats
- **GNU coreutils**: `sha256sum` format
- **BSD**: `md5 -r` format
- **SFV**: Simple File Verification
- **PAR2**: Parity archive (error correction)

### Industry Usage
- **Linux distributions**: Provide SHA-256 checksums for all ISOs
- **Software publishers**: Include checksums in release notes
- **Package managers**: Verify downloaded packages (apt, yum, brew)
- **Git**: Uses SHA-1 for commit IDs (migrating to SHA-256)
- **Blockchain**: Uses SHA-256 extensively (Bitcoin, Ethereum)

### Digital Forensics
- **Chain of custody**: Checksums prove evidence wasn't altered
- **E-discovery**: Verify document integrity in legal proceedings
- **Incident response**: Identify compromised files
- **File carving**: Verify recovered files

---

## Learn More

**Next Steps:**
1. Understand [[SHA256-Hash-Implementation]] for algorithm details
2. Learn [[Password-Strength-Analyzer]] for security principles
3. Explore digital signatures: GPG, code signing certificates

**External Resources:**
- [NIST Hash Functions](https://csrc.nist.gov/projects/hash-functions)
- [sha256sum Manual](https://www.gnu.org/software/coreutils/manual/html_node/sha2-utilities.html)
- [Verifying Downloads (Ubuntu)](https://ubuntu.com/tutorials/how-to-verify-ubuntu)
- [Bit Rot Explained](https://en.wikipedia.org/wiki/Data_degradation)

**Best Practices:**
- âœ… Use SHA-256 or SHA-512 for new projects
- âœ… Verify checksums from trusted sources (HTTPS, signed)
- âœ… Check regularly for bit rot (monthly for critical data)
- âœ… Combine checksums with digital signatures
- âœ… Use 3-2-1 backup rule (3 copies, 2 media types, 1 offsite)
- âŒ Don't trust checksums from same untrusted source as file
- âŒ Don't use MD5 for security-critical applications
- âŒ Don't assume checksum match = file is safe (verify signature!)

---

---

## Navigation

[â† Back to Home](Home) | [Report Issue](https://github.com/Shiva-destroyer/CryptoSentinel/issues) | [View All Tools](Home#available-tools)

---

**Developed by:** saisrujanmurthy@gmail.com
